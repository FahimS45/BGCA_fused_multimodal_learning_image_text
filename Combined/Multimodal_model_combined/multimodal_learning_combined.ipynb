{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-14T18:22:56.917890Z",
     "iopub.status.busy": "2025-06-14T18:22:56.917556Z",
     "iopub.status.idle": "2025-06-14T18:23:04.036085Z",
     "shell.execute_reply": "2025-06-14T18:23:04.035384Z",
     "shell.execute_reply.started": "2025-06-14T18:22:56.917865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit,\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import densenet121\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, DeiTForImageClassification\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:23:04.037441Z",
     "iopub.status.busy": "2025-06-14T18:23:04.037123Z",
     "iopub.status.idle": "2025-06-14T18:23:04.042085Z",
     "shell.execute_reply": "2025-06-14T18:23:04.041254Z",
     "shell.execute_reply.started": "2025-06-14T18:23:04.037420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:23:04.043902Z",
     "iopub.status.busy": "2025-06-14T18:23:04.043590Z",
     "iopub.status.idle": "2025-06-14T18:23:04.115212Z",
     "shell.execute_reply": "2025-06-14T18:23:04.114368Z",
     "shell.execute_reply.started": "2025-06-14T18:23:04.043866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:23:07.909505Z",
     "iopub.status.busy": "2025-06-14T18:23:07.909158Z",
     "iopub.status.idle": "2025-06-14T18:23:07.914596Z",
     "shell.execute_reply": "2025-06-14T18:23:07.913633Z",
     "shell.execute_reply.started": "2025-06-14T18:23:07.909478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_dir, target_size=(224, 224)):\n",
    "\n",
    "    X = []\n",
    "\n",
    "    # Sort filenames to maintain the default order\n",
    "    for img_name in sorted(os.listdir(data_dir)):\n",
    "        img_path = os.path.join(data_dir, img_name)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert('RGB')  \n",
    "                img = img.resize(target_size)  \n",
    "                X.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    return X\n",
    "\n",
    "data_dir = '/kaggle/input/combined-dmid-inbreast-mias/Combined_malignant_non-malignant/Combined_malignant_non-malignant'\n",
    "X = load_and_preprocess_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:47:42.154978Z",
     "iopub.status.busy": "2025-06-14T18:47:42.154624Z",
     "iopub.status.idle": "2025-06-14T18:47:42.160410Z",
     "shell.execute_reply": "2025-06-14T18:47:42.159384Z",
     "shell.execute_reply.started": "2025-06-14T18:47:42.154952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file\n",
    "file_path = \"/kaggle/input/combined-dmid-inbreast-mias/Combined-multimodal-text-data-updated.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:47:55.185882Z",
     "iopub.status.busy": "2025-06-14T18:47:55.185577Z",
     "iopub.status.idle": "2025-06-14T18:47:55.191389Z",
     "shell.execute_reply": "2025-06-14T18:47:55.190399Z",
     "shell.execute_reply.started": "2025-06-14T18:47:55.185859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images = X\n",
    "label_mapping = {'Non-Malignant': 0, 'Malignant': 1}\n",
    "labels = df['Class'].map(label_mapping).values\n",
    "texts = df['Generated Sentence'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=torch.unique(torch.tensor(labels)).numpy(),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights_tensor = class_weights_tensor.to(device)\n",
    "\n",
    "print(f\"Class Weights on Device: {class_weights_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:47:58.724398Z",
     "iopub.status.busy": "2025-06-14T18:47:58.724124Z",
     "iopub.status.idle": "2025-06-14T18:47:58.730998Z",
     "shell.execute_reply": "2025-06-14T18:47:58.730078Z",
     "shell.execute_reply.started": "2025-06-14T18:47:58.724377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, image_data, text_data, labels, tokenizer, transform=None, max_text_length=512):\n",
    "\n",
    "        self.image_data = image_data\n",
    "        self.text_data = text_data\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.max_text_length = max_text_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Image data\n",
    "        image = self.image_data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Text data\n",
    "        text = self.text_data[idx]\n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_text_length,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Flatten input IDs and attention masks\n",
    "        input_ids = encoded_text[\"input_ids\"].flatten()\n",
    "        attention_mask = encoded_text[\"attention_mask\"].flatten()\n",
    "\n",
    "        # Labels\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"label\": label\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional Gated Cross-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:02.511413Z",
     "iopub.status.busy": "2025-06-14T18:48:02.511073Z",
     "iopub.status.idle": "2025-06-14T18:48:02.517952Z",
     "shell.execute_reply": "2025-06-14T18:48:02.517051Z",
     "shell.execute_reply.started": "2025-06-14T18:48:02.511386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GatedCrossAttention(nn.Module):\n",
    "    def __init__(self, query_dim, context_dim, hidden_dim):\n",
    "        super(GatedCrossAttention, self).__init__()\n",
    "        self.query_proj = nn.Linear(query_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(context_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(context_dim, hidden_dim)\n",
    "\n",
    "        # Gating mechanism\n",
    "        self.gate_fc = nn.Linear(query_dim + hidden_dim, hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, context):\n",
    "        Q = self.query_proj(query).unsqueeze(1)     # [B, 1, H]\n",
    "        K = self.key_proj(context).unsqueeze(1)     # [B, 1, H]\n",
    "        V = self.value_proj(context).unsqueeze(1)   # [B, 1, H]\n",
    "\n",
    "        attn_scores = torch.bmm(Q, K.transpose(1, 2))  # [B, 1, 1]\n",
    "        attn_weights = self.softmax(attn_scores)       # [B, 1, 1]\n",
    "        attended = torch.bmm(attn_weights, V).squeeze(1)  # [B, H]\n",
    "\n",
    "        # Project query into hidden space for fusion\n",
    "        query_proj = self.query_proj(query)  # [B, H]\n",
    "\n",
    "        # Gate computation\n",
    "        gate_input = torch.cat([query, attended], dim=1)  # [B, Q+H]\n",
    "        gate = self.sigmoid(self.gate_fc(gate_input))     # [B, H]\n",
    "\n",
    "        # Gated fusion\n",
    "        gated_output = gate * query_proj + (1 - gate) * attended  # [B, H]\n",
    "        return gated_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:06.257249Z",
     "iopub.status.busy": "2025-06-14T18:48:06.256967Z",
     "iopub.status.idle": "2025-06-14T18:48:06.263813Z",
     "shell.execute_reply": "2025-06-14T18:48:06.262965Z",
     "shell.execute_reply.started": "2025-06-14T18:48:06.257227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiModalModelGatedCrossAttention(nn.Module):\n",
    "    def __init__(self, resnet_model, deit_model, text_model, fc_network):\n",
    "        super(MultiModalModelGatedCrossAttention, self).__init__()\n",
    "        self.resnet_model = resnet_model\n",
    "        self.deit_model = deit_model\n",
    "        self.text_model = text_model\n",
    "\n",
    "        self.resnet_dim = 2048\n",
    "        self.deit_dim = 768\n",
    "        self.text_dim = 768\n",
    "\n",
    "        self.fc_network = fc_network\n",
    "\n",
    "        self.vision_dim = self.resnet_dim + self.deit_dim\n",
    "        self.hidden_dim = 512  \n",
    "\n",
    "        # Gated cross attention: both directions\n",
    "        self.text_to_vision = GatedCrossAttention(self.text_dim, self.vision_dim, self.hidden_dim)\n",
    "        self.vision_to_text = GatedCrossAttention(self.vision_dim, self.text_dim, self.hidden_dim)\n",
    "\n",
    "    def forward(self, image_input, input_ids, attention_mask):\n",
    "\n",
    "        # Extract image features\n",
    "        resnet_features = self.resnet_model(image_input)                  # [B, 2048]\n",
    "        deit_features = self.deit_model(image_input).logits              # [B, 768]\n",
    "        vision_features = torch.cat([resnet_features, deit_features], dim=1)  # [B, 2816]\n",
    "\n",
    "        # Extract text features from [CLS] token of last hidden state\n",
    "        text_outputs = self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        text_features = text_outputs.hidden_states[-1][:, 0, :]          # [B, 768]\n",
    "\n",
    "        # Gated Cross Attention both directions\n",
    "        enhanced_text = self.text_to_vision(text_features, vision_features)    # [B, 512]\n",
    "        enhanced_vision = self.vision_to_text(vision_features, text_features)  # [B, 512]\n",
    "\n",
    "        # Final fused representation\n",
    "        fused = torch.cat([enhanced_text, enhanced_vision], dim=1)       # [B, 1024]\n",
    "\n",
    "        output = self.fc_network(fused)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:12.859310Z",
     "iopub.status.busy": "2025-06-14T18:48:12.858957Z",
     "iopub.status.idle": "2025-06-14T18:48:12.865093Z",
     "shell.execute_reply": "2025-06-14T18:48:12.864344Z",
     "shell.execute_reply.started": "2025-06-14T18:48:12.859258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    \n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "\n",
    "        # Move data to the device\n",
    "        images = batch[\"image\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    # Step the scheduler every epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:15.245741Z",
     "iopub.status.busy": "2025-06-14T18:48:15.245456Z",
     "iopub.status.idle": "2025-06-14T18:48:15.252532Z",
     "shell.execute_reply": "2025-06-14T18:48:15.251569Z",
     "shell.execute_reply.started": "2025-06-14T18:48:15.245721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    \n",
    "    model.eval()  \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "\n",
    "            # Move data to the device\n",
    "            images = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    true_labels = torch.stack(true_labels).cpu()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_accuracy, classification_report(\n",
    "        true_labels, predictions, target_names=df['Class'].unique(), output_dict=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:16.221098Z",
     "iopub.status.busy": "2025-06-14T18:48:16.220799Z",
     "iopub.status.idle": "2025-06-14T18:48:16.227408Z",
     "shell.execute_reply": "2025-06-14T18:48:16.226460Z",
     "shell.execute_reply.started": "2025-06-14T18:48:16.221075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(true_labels, predictions, save_cm_path, class_names=['Non-malignant', 'Malignant']):\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(save_cm_path), exist_ok=True)\n",
    "\n",
    "    # Generate Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    # Plot Confusion Matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, \n",
    "                yticklabels=class_names, linewidths=2, cbar=False, square=True, annot_kws={\"size\": 14})\n",
    "    \n",
    "    plt.xlabel('Predicted Labels', fontsize=12)\n",
    "    plt.ylabel('True Labels', fontsize=12)\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "\n",
    "    # Save confusion matrix as PDF\n",
    "    plt.savefig(save_cm_path, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved as {save_cm_path}\")\n",
    "\n",
    "    # Return classification report\n",
    "    return classification_report(true_labels, predictions, target_names=class_names, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:18.854120Z",
     "iopub.status.busy": "2025-06-14T18:48:18.853815Z",
     "iopub.status.idle": "2025-06-14T18:48:18.864623Z",
     "shell.execute_reply": "2025-06-14T18:48:18.863517Z",
     "shell.execute_reply.started": "2025-06-14T18:48:18.854096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, val_loader, criterion, device, seed=None, report_save_path=None):\n",
    "    \n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluation\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            predictions.extend(preds.cpu())\n",
    "            true_labels.extend(labels.cpu())\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            probabilities.extend(probs.cpu())\n",
    "\n",
    "    predictions = torch.stack(predictions)\n",
    "    true_labels = torch.stack(true_labels)\n",
    "    probabilities = torch.stack(probabilities)\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='macro')\n",
    "    recall = recall_score(true_labels, predictions, average='macro')\n",
    "    f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    auc_roc = roc_auc_score(true_labels, probabilities[:, 1], multi_class=\"ovr\") if probabilities.shape[1] > 1 else None\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if auc_roc is not None:\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    save_cm_path = '/kaggle/working/confusion_matrix.pdf'\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Non-malignant', 'Malignant'],\n",
    "                yticklabels=['Non-malignant', 'Malignant'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(save_cm_path)\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    class_report = classification_report(\n",
    "        true_labels,\n",
    "        predictions,\n",
    "        target_names=['Non-malignant', 'Malignant'],\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    # Return metrics summary and full classification report\n",
    "    results_df = pd.DataFrame([{\n",
    "        'Seed': seed if seed is not None else 'N/A',\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': auc_roc\n",
    "    }])\n",
    "\n",
    "    return results_df, class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:52:03.512835Z",
     "iopub.status.busy": "2025-06-14T14:52:03.512487Z",
     "iopub.status.idle": "2025-06-14T14:52:03.518323Z",
     "shell.execute_reply": "2025-06-14T14:52:03.517438Z",
     "shell.execute_reply.started": "2025-06-14T14:52:03.512797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:52:06.622227Z",
     "iopub.status.busy": "2025-06-14T14:52:06.621895Z",
     "iopub.status.idle": "2025-06-14T14:52:06.632243Z",
     "shell.execute_reply": "2025-06-14T14:52:06.631456Z",
     "shell.execute_reply.started": "2025-06-14T14:52:06.622198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model dimensions\n",
    "input_dim = 1024  # Refined features\n",
    "hidden_dim = 512\n",
    "output_dim = 2  # Number of classes (Non-malignant, Malignant)\n",
    "\n",
    "# Initialize the fully connected network\n",
    "fc_network = FullyConnectedNetwork(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal learning (DenseNet121+Deit+BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained DenseNet121 model\n",
    "def load_densenet_model(weight_path):\n",
    "     \n",
    "    densenet_model = densenet121(pretrained=False)\n",
    "    num_features = densenet_model.classifier.in_features\n",
    "    densenet_model.classifier = torch.nn.Identity()  \n",
    "    \n",
    "    # Load the state_dict\n",
    "    state_dict = torch.load(weight_path, map_location=torch.device('cpu'))  \n",
    "    state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"classifier.\")}\n",
    "    \n",
    "    # Load the pruned state_dict into the model\n",
    "    densenet_model.load_state_dict(state_dict, strict=False)\n",
    "    densenet_model.eval() \n",
    "    \n",
    "    for param in densenet_model.parameters():\n",
    "        param.requires_grad = False  \n",
    "    \n",
    "    return densenet_model\n",
    "\n",
    "\n",
    "# Load the pretrained DeiT model\n",
    "def load_deit_model(weight_path, num_classes=2):\n",
    "\n",
    "    deit_model = DeiTForImageClassification.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")\n",
    "    \n",
    "    # Remove classifier for feature extraction\n",
    "    deit_model.classifier = nn.Identity()  \n",
    "\n",
    "    # Load trained weights\n",
    "    state_dict = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "    deit_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    deit_model.eval()\n",
    "\n",
    "    # Freeze parameters\n",
    "    for param in deit_model.parameters():\n",
    "        param.requires_grad = False  \n",
    "\n",
    "    return deit_model\n",
    "    \n",
    "\n",
    "# Load the pretrained BioBERT model\n",
    "def load_bert_model(weight_path, bert_model_name='bert-base-uncased'):\n",
    "    \n",
    "    # Load the BERT tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "    \n",
    "    # Initialize the model with the same configuration used during training\n",
    "    bert_model = BertForSequenceClassification.from_pretrained(bert_model_name, num_labels=2)  \n",
    "\n",
    "    # Load the state_dict into the model\n",
    "    state_dict = torch.load(weight_path, map_location=torch.device('cpu'))  \n",
    "\n",
    "    # Load the state dict into the model \n",
    "    bert_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    bert_model.eval()\n",
    "\n",
    "    # Freeze the parameters of the model (for feature extraction)\n",
    "    for param in bert_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    return bert_model, tokenizer\n",
    "\n",
    "# Paths to saved model weights\n",
    "densenet_weight_path = \"/kaggle/input/densenet121-best-model-combined/pytorch/default/densenet_best_model.pth\"\n",
    "deit_weight_path = \"/kaggle/input/deit-combined/pytorch/default/deit_best_model.pth\"\n",
    "bert_weight_path = \"/kaggle/input/bert-best-model-combined/pytorch/default/best_bert_model.bin\"\n",
    "\n",
    "# Load the pretrained models for feature extraction\n",
    "densenet_model = load_densenet_model(densenet_weight_path)\n",
    "deit_model = load_deit_model(deit_weight_path)\n",
    "text_model, bert_tokenizer = load_bert_model(bert_weight_path)\n",
    "\n",
    "print(\"Models loaded and ready for feature extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_multimodal_data(df, X, seed=42):\n",
    "    \n",
    "    # Step 1: Split dataframe by source\n",
    "    df_inbreast = df[df['source'] == 'INbreast'].copy()\n",
    "    df_others = df[df['source'] != 'INbreast'].copy()\n",
    "\n",
    "    # Step 2: Extract report_id for GroupShuffleSplit\n",
    "    def extract_report_id(filename):\n",
    "        parts = filename.split('_')\n",
    "        return parts[1] if len(parts) > 2 else None\n",
    "\n",
    "    df_inbreast['report_id'] = df_inbreast['Image Name'].apply(extract_report_id)\n",
    "\n",
    "    # Step 3: Prepare INbreast variables\n",
    "    inb_texts = df_inbreast['Sentences'].values\n",
    "    inb_labels = df_inbreast['Class'].values\n",
    "    inb_images = X[:308]\n",
    "    inb_groups = df_inbreast['report_id'].values\n",
    "\n",
    "    # Step 4: INbreast GroupShuffleSplit (Train+Val vs Test)\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=seed)\n",
    "    train_val_idx, test_idx = next(gss.split(inb_texts, inb_labels, groups=inb_groups))\n",
    "\n",
    "    inb_texts_train_val, inb_texts_test = inb_texts[train_val_idx], inb_texts[test_idx]\n",
    "    inb_images_train_val = [inb_images[i] for i in train_val_idx]\n",
    "    inb_images_test = [inb_images[i] for i in test_idx]\n",
    "    inb_labels_train_val, inb_labels_test = inb_labels[train_val_idx], inb_labels[test_idx]\n",
    "    group_ids_train_val = inb_groups[train_val_idx]\n",
    "\n",
    "    # Step 5: INbreast Train vs Val GroupShuffleSplit\n",
    "    gss2 = GroupShuffleSplit(n_splits=1, test_size=0.176, random_state=seed)\n",
    "    train_idx, val_idx = next(gss2.split(inb_texts_train_val, inb_labels_train_val, groups=group_ids_train_val))\n",
    "\n",
    "    inb_texts_train, inb_texts_val = inb_texts_train_val[train_idx], inb_texts_train_val[val_idx]\n",
    "    inb_images_train = [inb_images_train_val[i] for i in train_idx]\n",
    "    inb_images_val = [inb_images_train_val[i] for i in val_idx]\n",
    "    inb_labels_train, inb_labels_val = inb_labels_train_val[train_idx], inb_labels_train_val[val_idx]\n",
    "\n",
    "    # Step 6: DMID & MIAS Train vs Val split\n",
    "    texts_others = df_others['Sentences'].values\n",
    "    labels_others = df_others['Class'].values\n",
    "    images_others = X[308:]\n",
    "\n",
    "    texts_others_train_val, texts_others_test, labels_others_train_val, labels_others_test, images_others_train_val, images_others_test = train_test_split(\n",
    "        texts_others, labels_others, images_others, test_size=0.15, stratify=labels_others, random_state=seed\n",
    "    )\n",
    "\n",
    "    texts_others_train, texts_others_val, labels_others_train, labels_others_val, images_others_train, images_others_val = train_test_split(\n",
    "        texts_others_train_val, labels_others_train_val, images_others_train_val, test_size=0.176, stratify=labels_others_train_val, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Step 8: Final concatenation\n",
    "    texts_train = np.concatenate([inb_texts_train, texts_others_train])\n",
    "    labels_train = np.concatenate([inb_labels_train, labels_others_train])\n",
    "    images_train = np.concatenate([inb_images_train, images_others_train])\n",
    "\n",
    "    texts_val = np.concatenate([inb_texts_val, texts_others_val])\n",
    "    labels_val = np.concatenate([inb_labels_val, labels_others_val])\n",
    "    images_val = np.concatenate([inb_images_val, images_others_val])\n",
    "\n",
    "    texts_test = np.concatenate([inb_texts_test, texts_others_test])\n",
    "    labels_test = np.concatenate([inb_labels_test, labels_others_test])\n",
    "    images_test = np.concatenate([inb_images_test, images_others_test])\n",
    "\n",
    "    return texts_train, labels_train, images_train, texts_val, labels_val, images_val, texts_test, labels_test, images_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments across 10 different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments_over_seeds(seed_list, df, images, cnn_weight_path, vit_weight_path, bert_weight_path, fc_network, class_weights_tensor):\n",
    "    \n",
    "    all_val_reports = []\n",
    "    all_test_reports = []\n",
    "    all_test_auc_roc_scores = []\n",
    "    \n",
    "    for seed in seed_list:\n",
    "        print(f\"\\n====== Running for Seed: {seed} ======\")\n",
    "        \n",
    "        # Set seed\n",
    "        def seed_worker(worker_id): np.random.seed(seed); random.seed(seed)\n",
    "        set_seed(seed)\n",
    "        \n",
    "        # Reload all models fresh for this seed\n",
    "        densenet_model = load_densenet_model(cnn_weight_path)\n",
    "        deit_model = load_deit_model(vit_weight_path)\n",
    "        text_model, bert_tokenizer = load_bert_model(bert_weight_path)\n",
    "        \n",
    "        # Data splitting\n",
    "        (texts_train, labels_train, images_train,\n",
    "        texts_val, labels_val, images_val,\n",
    "        texts_test, labels_test, images_test) = preprocess_multimodal_data(df, images, seed=seed)\n",
    "\n",
    "        # Datasets\n",
    "        train_dataset = MultiModalDataset(images_train, texts_train, labels_train, bert_tokenizer, train_transform)\n",
    "        val_dataset   = MultiModalDataset(images_val, texts_val, labels_val, bert_tokenizer, val_test_transform)\n",
    "        test_dataset  = MultiModalDataset(images_test, texts_test, labels_test, bert_tokenizer, val_test_transform)\n",
    "\n",
    "        # Loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, worker_init_fn=seed_worker)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, worker_init_fn=seed_worker)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, worker_init_fn=seed_worker)\n",
    "\n",
    "        # Model and training setup\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = MultiModalModelGatedCrossAttention(densenet_model, deit_model, text_model, fc_network).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)\n",
    "        optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-2)\n",
    "        scheduler = StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "        best_val_f1 = 0\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Store loss history\n",
    "        mm_train_losses = []\n",
    "        mm_val_losses = []\n",
    "\n",
    "        for epoch in range(100):\n",
    "            train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "            val_loss, val_acc, val_report = evaluate_model(model, val_loader, criterion, device)\n",
    "            val_f1 = val_report['macro avg']['f1-score']\n",
    "\n",
    "            mm_train_losses.append(train_loss)\n",
    "            mm_val_losses.append(val_loss)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:03d} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                torch.save(model.state_dict(), f\"best_model_seed_{seed}.bin\")\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 10:\n",
    "                    print(\"Early stopping.\")\n",
    "                    break\n",
    "\n",
    "        # Load best model and evaluate on test\n",
    "        model.load_state_dict(torch.load(f\"best_model_seed_{seed}.bin\"))\n",
    "        \n",
    "        # Modify the call to test_model to also return the results_df\n",
    "        # Assuming test_model now returns (results_df, classification_report)\n",
    "        results_df_test, test_report = test_model(model, test_loader, criterion, device)\n",
    "\n",
    "        all_val_reports.append(val_report)\n",
    "        all_test_reports.append(test_report)\n",
    "        \n",
    "        # Extract AUC-ROC score from results_df_test and append to its dedicated list\n",
    "        # Assuming AUC-ROC is a single value in the DataFrame, likely in the first row\n",
    "        if not results_df_test.empty and 'AUC-ROC' in results_df_test.columns:\n",
    "            auc_roc_score = results_df_test['AUC-ROC'].iloc[0]\n",
    "            all_test_auc_roc_scores.append(auc_roc_score)\n",
    "        else:\n",
    "            print(f\"Warning: AUC-ROC score not found in results_df_test for seed {seed}\")\n",
    "            all_test_auc_roc_scores.append(None) # Append None or handle as appropriate\n",
    "            \n",
    "\n",
    "        # Plot training and validation loss curves for this seed\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, len(mm_train_losses) + 1), mm_train_losses, label='Training Loss')\n",
    "        plt.plot(range(1, len(mm_val_losses) + 1), mm_val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Training and Validation Loss (Seed {seed})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Return all collected reports and the new AUC-ROC scores list\n",
    "    return all_val_reports, all_test_reports, all_test_auc_roc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [42, 77, 7, 101, 314, 2024, 123, 88, 11, 99]\n",
    "\n",
    "val_results, test_results, test_auc_roc = run_experiments_over_seeds(\n",
    "    seed_list,\n",
    "    df=df, images=X,\n",
    "    cnn_weight_path=densenet_weight_path,\n",
    "    vit_weight_path=deit_weight_path,\n",
    "    bert_weight_path=bert_weight_path,\n",
    "    fc_network=fc_network, class_weights_tensor=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(data, n_bootstrap=10000, ci=95):\n",
    "    \n",
    "    data = np.array(data)\n",
    "    means = []\n",
    "    n = len(data)\n",
    "    if n == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        means.append(np.mean(sample))\n",
    "    lower = np.percentile(means, (100 - ci) / 2)\n",
    "    upper_percentile = 100 - (100 - ci) / 2\n",
    "    upper = np.percentile(means, upper_percentile)\n",
    "    return np.mean(means), lower, upper\n",
    "\n",
    "def evaluate_metrics_with_bootstrap(test_reports, auc_roc_scores, n_bootstrap=10000, ci=95):\n",
    "\n",
    "    macro_f1_scores = []\n",
    "    accuracies = []\n",
    "    macro_precisions = []\n",
    "    macro_recalls = []\n",
    "\n",
    "    for report in test_reports:\n",
    "        macro_f1_scores.append(report[\"macro avg\"][\"f1-score\"])\n",
    "        macro_precisions.append(report[\"macro avg\"][\"precision\"])\n",
    "        macro_recalls.append(report[\"macro avg\"][\"recall\"])\n",
    "        accuracies.append(report[\"accuracy\"])\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Accuracy': accuracies,\n",
    "        'Precision': macro_precisions,\n",
    "        'Recall': macro_recalls,\n",
    "        'F1-Score': macro_f1_scores,\n",
    "        'AUC-ROC': auc_roc_scores\n",
    "    })\n",
    "\n",
    "    metrics_to_bootstrap = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "\n",
    "    summary_rows = []\n",
    "    for metric in metrics_to_bootstrap:\n",
    "        values = metrics_df[metric].dropna().values\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        boot_mean, ci_lower, ci_upper = bootstrap_ci(values, n_bootstrap=n_bootstrap, ci=ci)\n",
    "        summary_rows.append({\n",
    "            'Metric': metric,\n",
    "            'Mean': mean_val,\n",
    "            'Std Dev': std_val,\n",
    "            'Boot Mean': boot_mean,\n",
    "            f'{ci}% CI Lower': ci_lower,\n",
    "            f'{ci}% CI Upper': ci_upper\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "    # Print individual results\n",
    "    print(\"===== Individual Seed Run Results =====\")\n",
    "    for i, (acc, f1, prec, rec, roc_auc) in enumerate(zip(\n",
    "        metrics_df['Accuracy'], metrics_df['F1-Score'], metrics_df['Precision'],\n",
    "        metrics_df['Recall'], metrics_df['AUC-ROC']), 1):\n",
    "        print(f\"Seed Run {i}:\")\n",
    "        print(f\"  Accuracy        : {acc:.4f}\")\n",
    "        print(f\"  Macro F1-score  : {f1:.4f}\")\n",
    "        print(f\"  Macro Precision : {prec:.4f}\")\n",
    "        print(f\"  Macro Recall    : {rec:.4f}\")\n",
    "        print(f\"  AUC-ROC         : {roc_auc:.4f}\\n\")\n",
    "\n",
    "    # Print the aggregated summary\n",
    "    print(\"===== Aggregated Results (Mean ± Std & Bootstrap CI) =====\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        print(f\"{row['Metric']}:\")\n",
    "        print(f\"  Mean ± Std        : {row['Mean']:.4f} ± {row['Std Dev']:.4f}\")\n",
    "        print(f\"  {ci}% CI (Bootstrap): [{row[f'{ci}% CI Lower']:.4f}, {row[f'{ci}% CI Upper']:.4f}]\\n\")\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = evaluate_metrics_with_bootstrap(test_reports=test_results, auc_roc_scores=test_auc_roc)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6077997,
     "sourceId": 10813167,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186515,
     "modelInstanceId": 164168,
     "sourceId": 196156,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 186519,
     "modelInstanceId": 164172,
     "sourceId": 204311,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186508,
     "modelInstanceId": 164161,
     "sourceId": 247080,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 189730,
     "modelInstanceId": 167412,
     "sourceId": 249391,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186519,
     "modelInstanceId": 164172,
     "sourceId": 412421,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186521,
     "modelInstanceId": 164174,
     "sourceId": 412433,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186527,
     "modelInstanceId": 164180,
     "sourceId": 412437,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
