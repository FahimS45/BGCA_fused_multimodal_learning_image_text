{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-14T18:22:56.917890Z",
     "iopub.status.busy": "2025-06-14T18:22:56.917556Z",
     "iopub.status.idle": "2025-06-14T18:23:04.036085Z",
     "shell.execute_reply": "2025-06-14T18:23:04.035384Z",
     "shell.execute_reply.started": "2025-06-14T18:22:56.917865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet152\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, DeiTForImageClassification\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:23:04.037441Z",
     "iopub.status.busy": "2025-06-14T18:23:04.037123Z",
     "iopub.status.idle": "2025-06-14T18:23:04.042085Z",
     "shell.execute_reply": "2025-06-14T18:23:04.041254Z",
     "shell.execute_reply.started": "2025-06-14T18:23:04.037420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:23:04.043902Z",
     "iopub.status.busy": "2025-06-14T18:23:04.043590Z",
     "iopub.status.idle": "2025-06-14T18:23:04.115212Z",
     "shell.execute_reply": "2025-06-14T18:23:04.114368Z",
     "shell.execute_reply.started": "2025-06-14T18:23:04.043866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:23:07.909505Z",
     "iopub.status.busy": "2025-06-14T18:23:07.909158Z",
     "iopub.status.idle": "2025-06-14T18:23:07.914596Z",
     "shell.execute_reply": "2025-06-14T18:23:07.913633Z",
     "shell.execute_reply.started": "2025-06-14T18:23:07.909478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_dir, target_size=(224, 224)):\n",
    "\n",
    "    X = []\n",
    "\n",
    "    # Sort filenames to maintain the default order\n",
    "    for img_name in sorted(os.listdir(data_dir)):\n",
    "        img_path = os.path.join(data_dir, img_name)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert('RGB')  \n",
    "                img = img.resize(target_size)  \n",
    "                X.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    return X\n",
    "\n",
    "data_dir = '/kaggle/input/mammography/DMID_malignant_non-malignant/DMID_malignant_non-malignant'\n",
    "X = load_and_preprocess_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:47:42.154978Z",
     "iopub.status.busy": "2025-06-14T18:47:42.154624Z",
     "iopub.status.idle": "2025-06-14T18:47:42.160410Z",
     "shell.execute_reply": "2025-06-14T18:47:42.159384Z",
     "shell.execute_reply.started": "2025-06-14T18:47:42.154952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file\n",
    "file_path = \"/kaggle/input/mammography/mammography-text.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:47:55.185882Z",
     "iopub.status.busy": "2025-06-14T18:47:55.185577Z",
     "iopub.status.idle": "2025-06-14T18:47:55.191389Z",
     "shell.execute_reply": "2025-06-14T18:47:55.190399Z",
     "shell.execute_reply.started": "2025-06-14T18:47:55.185859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images = X\n",
    "label_mapping = {'Non-Malignant': 0, 'Malignant': 1}\n",
    "labels = df['Class'].map(label_mapping).values\n",
    "texts = df['Generated Sentence'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=torch.unique(torch.tensor(labels)).numpy(),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights_tensor = class_weights_tensor.to(device)\n",
    "\n",
    "print(f\"Class Weights on Device: {class_weights_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:47:58.724398Z",
     "iopub.status.busy": "2025-06-14T18:47:58.724124Z",
     "iopub.status.idle": "2025-06-14T18:47:58.730998Z",
     "shell.execute_reply": "2025-06-14T18:47:58.730078Z",
     "shell.execute_reply.started": "2025-06-14T18:47:58.724377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, image_data, text_data, labels, tokenizer, transform=None, max_text_length=512):\n",
    "\n",
    "        self.image_data = image_data\n",
    "        self.text_data = text_data\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.max_text_length = max_text_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Image data\n",
    "        image = self.image_data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Text data\n",
    "        text = self.text_data[idx]\n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_text_length,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Flatten input IDs and attention masks\n",
    "        input_ids = encoded_text[\"input_ids\"].flatten()\n",
    "        attention_mask = encoded_text[\"attention_mask\"].flatten()\n",
    "\n",
    "        # Labels\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"label\": label\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional Gated Cross-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:02.511413Z",
     "iopub.status.busy": "2025-06-14T18:48:02.511073Z",
     "iopub.status.idle": "2025-06-14T18:48:02.517952Z",
     "shell.execute_reply": "2025-06-14T18:48:02.517051Z",
     "shell.execute_reply.started": "2025-06-14T18:48:02.511386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GatedCrossAttention(nn.Module):\n",
    "    def __init__(self, query_dim, context_dim, hidden_dim):\n",
    "        super(GatedCrossAttention, self).__init__()\n",
    "        self.query_proj = nn.Linear(query_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(context_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(context_dim, hidden_dim)\n",
    "\n",
    "        # Gating mechanism\n",
    "        self.gate_fc = nn.Linear(query_dim + hidden_dim, hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, context):\n",
    "        Q = self.query_proj(query).unsqueeze(1)     # [B, 1, H]\n",
    "        K = self.key_proj(context).unsqueeze(1)     # [B, 1, H]\n",
    "        V = self.value_proj(context).unsqueeze(1)   # [B, 1, H]\n",
    "\n",
    "        attn_scores = torch.bmm(Q, K.transpose(1, 2))  # [B, 1, 1]\n",
    "        attn_weights = self.softmax(attn_scores)       # [B, 1, 1]\n",
    "        attended = torch.bmm(attn_weights, V).squeeze(1)  # [B, H]\n",
    "\n",
    "        # Project query into hidden space for fusion\n",
    "        query_proj = self.query_proj(query)  # [B, H]\n",
    "\n",
    "        # Gate computation\n",
    "        gate_input = torch.cat([query, attended], dim=1)  # [B, Q+H]\n",
    "        gate = self.sigmoid(self.gate_fc(gate_input))     # [B, H]\n",
    "\n",
    "        # Gated fusion\n",
    "        gated_output = gate * query_proj + (1 - gate) * attended  # [B, H]\n",
    "        return gated_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:06.257249Z",
     "iopub.status.busy": "2025-06-14T18:48:06.256967Z",
     "iopub.status.idle": "2025-06-14T18:48:06.263813Z",
     "shell.execute_reply": "2025-06-14T18:48:06.262965Z",
     "shell.execute_reply.started": "2025-06-14T18:48:06.257227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiModalModelGatedCrossAttention(nn.Module):\n",
    "    def __init__(self, resnet_model, deit_model, text_model, fc_network):\n",
    "        super(MultiModalModelGatedCrossAttention, self).__init__()\n",
    "        self.resnet_model = resnet_model\n",
    "        self.deit_model = deit_model\n",
    "        self.text_model = text_model\n",
    "\n",
    "        self.resnet_dim = 2048\n",
    "        self.deit_dim = 768\n",
    "        self.text_dim = 768\n",
    "\n",
    "        self.fc_network = fc_network\n",
    "\n",
    "        self.vision_dim = self.resnet_dim + self.deit_dim\n",
    "        self.hidden_dim = 512  \n",
    "\n",
    "        # Gated cross attention: both directions\n",
    "        self.text_to_vision = GatedCrossAttention(self.text_dim, self.vision_dim, self.hidden_dim)\n",
    "        self.vision_to_text = GatedCrossAttention(self.vision_dim, self.text_dim, self.hidden_dim)\n",
    "\n",
    "    def forward(self, image_input, input_ids, attention_mask):\n",
    "\n",
    "        # Extract image features\n",
    "        resnet_features = self.resnet_model(image_input)                  # [B, 2048]\n",
    "        deit_features = self.deit_model(image_input).logits              # [B, 768]\n",
    "        vision_features = torch.cat([resnet_features, deit_features], dim=1)  # [B, 2816]\n",
    "\n",
    "        # Extract text features from [CLS] token of last hidden state\n",
    "        text_outputs = self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        text_features = text_outputs.hidden_states[-1][:, 0, :]          # [B, 768]\n",
    "\n",
    "        # Gated Cross Attention both directions\n",
    "        enhanced_text = self.text_to_vision(text_features, vision_features)    # [B, 512]\n",
    "        enhanced_vision = self.vision_to_text(vision_features, text_features)  # [B, 512]\n",
    "\n",
    "        # Final fused representation\n",
    "        fused = torch.cat([enhanced_text, enhanced_vision], dim=1)       # [B, 1024]\n",
    "\n",
    "        output = self.fc_network(fused)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:12.859310Z",
     "iopub.status.busy": "2025-06-14T18:48:12.858957Z",
     "iopub.status.idle": "2025-06-14T18:48:12.865093Z",
     "shell.execute_reply": "2025-06-14T18:48:12.864344Z",
     "shell.execute_reply.started": "2025-06-14T18:48:12.859258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "\n",
    "        # Move data to the device\n",
    "        images = batch[\"image\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    # Step the scheduler every epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:15.245741Z",
     "iopub.status.busy": "2025-06-14T18:48:15.245456Z",
     "iopub.status.idle": "2025-06-14T18:48:15.252532Z",
     "shell.execute_reply": "2025-06-14T18:48:15.251569Z",
     "shell.execute_reply.started": "2025-06-14T18:48:15.245721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()  \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "\n",
    "            # Move data to the device\n",
    "            images = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    true_labels = torch.stack(true_labels).cpu()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_accuracy, classification_report(\n",
    "        true_labels, predictions, target_names=df['Class'].unique(), output_dict=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:16.221098Z",
     "iopub.status.busy": "2025-06-14T18:48:16.220799Z",
     "iopub.status.idle": "2025-06-14T18:48:16.227408Z",
     "shell.execute_reply": "2025-06-14T18:48:16.226460Z",
     "shell.execute_reply.started": "2025-06-14T18:48:16.221075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(true_labels, predictions, save_cm_path, class_names=['Non-malignant', 'Malignant']):\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(save_cm_path), exist_ok=True)\n",
    "\n",
    "    # Generate Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    # Plot Confusion Matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, \n",
    "                yticklabels=class_names, linewidths=2, cbar=False, square=True, annot_kws={\"size\": 14})\n",
    "    \n",
    "    plt.xlabel('Predicted Labels', fontsize=12)\n",
    "    plt.ylabel('True Labels', fontsize=12)\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "\n",
    "    # Save confusion matrix as PDF\n",
    "    plt.savefig(save_cm_path, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved as {save_cm_path}\")\n",
    "\n",
    "    # Return classification report\n",
    "    return classification_report(true_labels, predictions, target_names=class_names, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T18:48:18.854120Z",
     "iopub.status.busy": "2025-06-14T18:48:18.853815Z",
     "iopub.status.idle": "2025-06-14T18:48:18.864623Z",
     "shell.execute_reply": "2025-06-14T18:48:18.863517Z",
     "shell.execute_reply.started": "2025-06-14T18:48:18.854096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, val_loader, criterion, device, seed=None, report_save_path=None):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluation\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            predictions.extend(preds.cpu())\n",
    "            true_labels.extend(labels.cpu())\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            probabilities.extend(probs.cpu())\n",
    "\n",
    "    predictions = torch.stack(predictions)\n",
    "    true_labels = torch.stack(true_labels)\n",
    "    probabilities = torch.stack(probabilities)\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='macro')\n",
    "    recall = recall_score(true_labels, predictions, average='macro')\n",
    "    f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    auc_roc = roc_auc_score(true_labels, probabilities[:, 1], multi_class=\"ovr\") if probabilities.shape[1] > 1 else None\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if auc_roc is not None:\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    save_cm_path = '/kaggle/working/confusion_matrix.pdf'\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Non-malignant', 'Malignant'],\n",
    "                yticklabels=['Non-malignant', 'Malignant'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(save_cm_path)\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    class_report = classification_report(\n",
    "        true_labels,\n",
    "        predictions,\n",
    "        target_names=['Non-malignant', 'Malignant'],\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    # Return metrics summary and full classification report\n",
    "    results_df = pd.DataFrame([{\n",
    "        'Seed': seed if seed is not None else 'N/A',\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': auc_roc\n",
    "    }])\n",
    "\n",
    "    return results_df, class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:52:03.512835Z",
     "iopub.status.busy": "2025-06-14T14:52:03.512487Z",
     "iopub.status.idle": "2025-06-14T14:52:03.518323Z",
     "shell.execute_reply": "2025-06-14T14:52:03.517438Z",
     "shell.execute_reply.started": "2025-06-14T14:52:03.512797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:52:06.622227Z",
     "iopub.status.busy": "2025-06-14T14:52:06.621895Z",
     "iopub.status.idle": "2025-06-14T14:52:06.632243Z",
     "shell.execute_reply": "2025-06-14T14:52:06.631456Z",
     "shell.execute_reply.started": "2025-06-14T14:52:06.622198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model dimensions\n",
    "input_dim = 1024  # Refined features\n",
    "hidden_dim = 512\n",
    "output_dim = 2  # Number of classes (Non-malignant, Malignant)\n",
    "\n",
    "# Initialize the fully connected network\n",
    "fc_network = FullyConnectedNetwork(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal learning (ResNet152+Deit+BioBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained ResNet152 model\n",
    "def load_resnet_model(weight_path):\n",
    "\n",
    "    resnet_model = resnet152(pretrained=False)\n",
    "    num_features = resnet_model.fc.in_features\n",
    "    resnet_model.fc = torch.nn.Identity()  \n",
    "    \n",
    "    # Load the state_dict\n",
    "    state_dict = torch.load(weight_path)\n",
    "    \n",
    "    # Remove \"fc.weight\" and \"fc.bias\" from the state_dict\n",
    "    state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
    "    \n",
    "    # Load the pruned state_dict into the model\n",
    "    resnet_model.load_state_dict(state_dict, strict=False)\n",
    "    resnet_model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    for param in resnet_model.parameters():\n",
    "        param.requires_grad = False  # Freeze all parameters\n",
    "    \n",
    "    return resnet_model\n",
    "\n",
    "\n",
    "# Load the pretrained DeiT model\n",
    "def load_deit_model(weight_path, num_classes=2):\n",
    "\n",
    "    deit_model = DeiTForImageClassification.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")\n",
    "    \n",
    "    # Remove classifier for feature extraction\n",
    "    deit_model.classifier = nn.Identity()  \n",
    "\n",
    "    # Load trained weights\n",
    "    state_dict = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "    deit_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    deit_model.eval()\n",
    "\n",
    "    # Freeze parameters\n",
    "    for param in deit_model.parameters():\n",
    "        param.requires_grad = False  \n",
    "\n",
    "    return deit_model\n",
    "    \n",
    "\n",
    "# Load the pretrained BioBERT model\n",
    "def load_bert_model(weight_path, bert_model_name='dmis-lab/biobert-v1.1'):\n",
    "    \n",
    "    # Load the BERT tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "    \n",
    "    # Initialize the model with the same configuration used during training\n",
    "    bert_model = BertForSequenceClassification.from_pretrained(bert_model_name, num_labels=2)  \n",
    "\n",
    "    # Load the state_dict into the model\n",
    "    state_dict = torch.load(weight_path, map_location=torch.device('cpu'))  \n",
    "\n",
    "    # Load the state dict into the model \n",
    "    bert_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    bert_model.eval()\n",
    "\n",
    "    # Freeze the parameters of the model (for feature extraction)\n",
    "    for param in bert_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    return bert_model, tokenizer\n",
    "\n",
    "# Paths to saved model weights\n",
    "resnet_weight_path = \"/kaggle/input/resnet152-best-model-mammo/pytorch/default/resnet_best_model.pth\"\n",
    "deit_weight_path = \"/kaggle/input/deit-mammo/pytorch/default/deit_best_model.pth\"\n",
    "bert_weight_path = \"/kaggle/input/biobert-best-model-mammo/pytorch/default/best_bio_model_state2.bin\"\n",
    "\n",
    "# Load the pretrained models for feature extraction\n",
    "resnet_model = load_resnet_model(resnet_weight_path)\n",
    "deit_model = load_deit_model(deit_weight_path)\n",
    "text_model, bert_tokenizer = load_bert_model(bert_weight_path)\n",
    "\n",
    "print(\"Models loaded and ready for feature extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments across 10 different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments_over_seeds_multimodal(seed_list, texts, images, labels,\n",
    "                                          train_transform, val_test_transform,\n",
    "                                          resnet_weight_path, deit_weight_path, bert_weight_path,\n",
    "                                          fc_network, class_weights_tensor):\n",
    "\n",
    "    test_reports = []\n",
    "    test_auc_roc = []\n",
    "\n",
    "    batch_size = 32\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for iteration, seed in enumerate(seed_list):\n",
    "        print(f\"\\n🔁 Running experiment with seed: {seed}\")\n",
    "        set_seed(seed)\n",
    "\n",
    "        def seed_worker(worker_id):\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        # === STEP 1: Load the models ===\n",
    "        resnet_model = load_resnet_model(resnet_weight_path)\n",
    "        deit_model = load_deit_model(deit_weight_path)\n",
    "        text_model, bert_tokenizer = load_bert_model(bert_weight_path)\n",
    "\n",
    "        # === STEP 2: Data split ===\n",
    "        texts_train_val, texts_test, images_train_val, images_test, labels_train_val, labels_test = train_test_split(\n",
    "            texts, images, labels, test_size=0.15, stratify=labels, random_state=seed\n",
    "        )\n",
    "        texts_train, texts_val, images_train, images_val, labels_train, labels_val = train_test_split(\n",
    "            texts_train_val, images_train_val, labels_train_val, test_size=0.176,\n",
    "            stratify=labels_train_val, random_state=seed\n",
    "        )\n",
    "\n",
    "        # === STEP 3: Create datasets and dataloaders ===\n",
    "        train_dataset = MultiModalDataset(images_train, texts_train, labels_train, bert_tokenizer, train_transform, 512)\n",
    "        val_dataset = MultiModalDataset(images_val, texts_val, labels_val, bert_tokenizer, val_test_transform, 512)\n",
    "        test_dataset = MultiModalDataset(images_test, texts_test, labels_test, bert_tokenizer, val_test_transform, 512)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker)\n",
    "\n",
    "        # === STEP 4: Initialize model and training tools ===\n",
    "        model = MultiModalModelGatedCrossAttention(\n",
    "            resnet_model, deit_model, text_model, fc_network\n",
    "        ).to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)\n",
    "        optimizer = Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=1e-5, weight_decay=1e-4\n",
    "        )\n",
    "        scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "\n",
    "        # === STEP 5: Train with Early Stopping ===\n",
    "        best_val_f1 = 0\n",
    "        patience_counter = 0\n",
    "        patience_limit = 10\n",
    "        num_epochs = 50\n",
    "\n",
    "        mm_train_losses = []\n",
    "        mm_val_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "            val_loss, val_acc, val_report = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "            mm_train_losses.append(train_loss)\n",
    "            mm_val_losses.append(val_loss)\n",
    "\n",
    "            val_f1 = val_report['macro avg']['f1-score']\n",
    "            print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f}\")\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                patience_counter = 0\n",
    "                print(\"✅ Improved F1. Saving model...\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience_limit:\n",
    "                    print(\"🛑 Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        # === STEP 6: Load best model and test ===\n",
    "        model.load_state_dict(best_model_state)\n",
    "        results_df, class_report = test_model(model, test_loader, criterion, device, seed=seed)\n",
    "\n",
    "        test_reports.append(class_report)\n",
    "        test_auc_roc.append(results_df[\"AUC-ROC\"].values[0])\n",
    "\n",
    "        # === STEP 7: Plot loss curves ===\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, len(mm_train_losses) + 1), mm_train_losses, label='Training Loss')\n",
    "        plt.plot(range(1, len(mm_val_losses) + 1), mm_val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Seed {seed} - Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return test_reports, test_auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [42, 77, 7, 101, 314, 2024, 123, 88, 11, 99]\n",
    "\n",
    "test_reports, test_auc_roc = run_experiments_over_seeds_multimodal(\n",
    "    seed_list=seed_list,\n",
    "    texts=texts,\n",
    "    images=images,\n",
    "    labels=labels,\n",
    "    train_transform=train_transform,\n",
    "    val_test_transform=val_test_transform,\n",
    "    resnet_weight_path=resnet_weight_path,\n",
    "    deit_weight_path=resnet_weight_path,\n",
    "    bert_weight_path=bert_weight_path,\n",
    "    fc_network=fc_network,\n",
    "    class_weights_tensor=class_weights_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(data, n_bootstrap=10000, ci=95):\n",
    "    data = np.array(data)\n",
    "    means = []\n",
    "    n = len(data)\n",
    "    if n == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        means.append(np.mean(sample))\n",
    "    lower = np.percentile(means, (100 - ci) / 2)\n",
    "    upper = np.percentile(means, 100 - (100 - ci) / 2)\n",
    "    return np.mean(means), lower, upper\n",
    "\n",
    "def analyze_multimodal_results(test_reports, test_auc_roc):\n",
    "    macro_f1_scores = []\n",
    "    accuracies = []\n",
    "    macro_precisions = []\n",
    "    macro_recalls = []\n",
    "    auc_roc_scores = test_auc_roc  # Directly assign if already a list\n",
    "\n",
    "    # Extract metrics from classification reports\n",
    "    for report in test_reports:\n",
    "        macro_f1_scores.append(report[\"macro avg\"][\"f1-score\"])\n",
    "        macro_precisions.append(report[\"macro avg\"][\"precision\"])\n",
    "        macro_recalls.append(report[\"macro avg\"][\"recall\"])\n",
    "        accuracies.append(report[\"accuracy\"])\n",
    "\n",
    "    print(\"===== Individual Seed Run Results =====\")\n",
    "    for i, (acc, f1, prec, rec, roc_auc) in enumerate(zip(accuracies, macro_f1_scores, macro_precisions, macro_recalls, auc_roc_scores), 1):\n",
    "        print(f\"Seed Run {i}:\")\n",
    "        print(f\"  Accuracy        : {acc:.4f}\")\n",
    "        print(f\"  Macro F1-score  : {f1:.4f}\")\n",
    "        print(f\"  Macro Precision : {prec:.4f}\")\n",
    "        print(f\"  Macro Recall    : {rec:.4f}\")\n",
    "        print(f\"  AUC-ROC         : {roc_auc:.4f}\")\n",
    "        print()\n",
    "\n",
    "    # Create DataFrame for metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Accuracy': accuracies,\n",
    "        'Precision': macro_precisions,\n",
    "        'Recall': macro_recalls,\n",
    "        'F1-Score': macro_f1_scores,\n",
    "        'AUC-ROC': auc_roc_scores\n",
    "    })\n",
    "\n",
    "    # Define which metrics to compute bootstrap CI for\n",
    "    metrics_to_bootstrap = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "\n",
    "    # Compute summary statistics and CIs\n",
    "    summary_rows = []\n",
    "    for metric in metrics_to_bootstrap:\n",
    "        mean_val = metrics_df[metric].mean()\n",
    "        std_val = metrics_df[metric].std()\n",
    "        boot_mean, ci_lower, ci_upper = bootstrap_ci(metrics_df[metric].dropna().values)\n",
    "\n",
    "        summary_rows.append({\n",
    "            'Metric': metric,\n",
    "            'Mean': mean_val,\n",
    "            'Std Dev': std_val,\n",
    "            'Boot Mean': boot_mean,\n",
    "            '95% CI Lower': ci_lower,\n",
    "            '95% CI Upper': ci_upper\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "    print(\"---\")\n",
    "    print(\"===== Aggregated Results (Mean ± Std & Bootstrap 95% CI) =====\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        print(f\"{row['Metric']}:\")\n",
    "        print(f\"  Mean ± Std       : {row['Mean']:.4f} ± {row['Std Dev']:.4f}\")\n",
    "        print(f\"  95% CI (Bootstrap): [{row['95% CI Lower']:.4f}, {row['95% CI Upper']:.4f}]\")\n",
    "        print()\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_multimodal_results(test_reports, test_auc_roc)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6077997,
     "sourceId": 10813167,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186515,
     "modelInstanceId": 164168,
     "sourceId": 196156,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 186519,
     "modelInstanceId": 164172,
     "sourceId": 204311,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186508,
     "modelInstanceId": 164161,
     "sourceId": 247080,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 189730,
     "modelInstanceId": 167412,
     "sourceId": 249391,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186519,
     "modelInstanceId": 164172,
     "sourceId": 412421,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186521,
     "modelInstanceId": 164174,
     "sourceId": 412433,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 186527,
     "modelInstanceId": 164180,
     "sourceId": 412437,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
